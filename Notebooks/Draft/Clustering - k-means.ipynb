{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de patrones: Identificación de grupos o Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distancias  y Grupos\n",
    "\n",
    "__Clustering__ se refiere a un conjunto muy amplio de técnicas para encontrar subgrupos, o grupos, en un conjunto de datos. Cuando agrupamos las observaciones de un conjunto de datos, buscamos dividirlas en grupos distintos para que las observaciones dentro de cada grupo sean bastante similares entre sí, al mismo tiempo que las observaciones en los diferentes grupos sean lo suficientemente diferentes entre ellas.\n",
    "\n",
    "Por supuesto, para hacer que esto sea concreto, debemos definir lo que significa que dos o más observaciones sean similares o diferentes. De hecho, esta es a menudo una consideración específica del dominio que debe realizarse en función del conocimiento de los datos que se estudian. Por ejemplo, supongamos que tenemos un conjunto de $n$ observaciones, cada una con $p$ características. Las $n$ observaciones podrían corresponder a muestras de tejido para pacientes con cáncer de mama, y las $p$ características corresponden a mediciones recogidas para cada muestra de tejido; estas podrían ser medidas clínicas, como la etapa o grado del tumor, o podrían ser mediciones de la expresión génica. Podemos tener una razón para creer que existe alguna heterogeneidad entre las n muestras de tejido; por ejemplo, tal vez haya algunos diferentes subtipos desconocidos de cáncer de mama. La agrupación podría usarse para encontrar estos subgrupos. Este es un problema no supervisado porque estamos tratando de descubrir la estructura (en este caso, clusters distintos) sobre la base de un conjunto de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición\n",
    "\n",
    "El reconocimiento de patrones se realiza en un ciclo de tres fases principales:\n",
    "\n",
    "1. La identificación o definición de clases en las que se pueden agrupar los elementos de un dominio de interés. Estas clases suelen ser creadas a partir de la observación de características que presentan los elementos bajo observación.\n",
    "2. La asignación de elementos (conocidos) a clases definidas.\n",
    "3. La predicción de nuevas observaciones dada la dinámica observada a partir del conjunto de clases.\n",
    "\n",
    "\n",
    "Para realizar la construcción de las clases a partir de observaciones, utilizamos un técnica conocida como  *identificación de grupos*, o más comunmente, \"*clustering*\".\n",
    "\n",
    "El clustering consiste en agrupar objetos en grupos de tal manera que los objetos pertenecientes a un grupo (o \"*cluster*\") son más semejantes entre sí que a otros objetos no pertenecientes al grupo.\n",
    "\n",
    "![](images/clusters_aficionados.jpg)\n",
    "![ ](images/blank.png)\n",
    "\n",
    "La semejanza se define a través de diversos rasgos, algunos de los cuales pueden ser de carácter semántico; En la imagen a continuación, por ejemplo, pueden distinguirse dos grupos principales de fans: los \"*amarillos*\" que junto con los \"*azules*\" forman el grupo de \"*fans brasileños*\" en oposición al grupo de fans \"*verdes*\" y fans \"*rojos*\" que conforman el grupo de \"*fans mexicanos*\".\n",
    "\n",
    "El agrupamiento es una habilidad natural de los seres vivos. Las relaciones de semejanza nos permiten identificar grupos incluso como si fueran objetos inexistentes:\n",
    "\n",
    "![](images/law-of-proximity.png)\n",
    "![ ](images/blank.png)\n",
    "![](images/Pattern1.jpg)\n",
    "![ ](images/blank.png)\n",
    "![ ](images/blank.png)\n",
    "![](images/gestalt_proximity_dalmation_by_gderanidaye.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Técnicas de clustering: *K-Means*\n",
    "\n",
    "La técnica de *k-medias* (o *k-means*) es una de las técnicas de clustering más simples y más utilizadas. Es una técnica de *aprendizaje no supervisado*: la técnica debe clasificar objetos desconocidos a un conjunto de clases de las que apenas se conocen algunos parámetros y no las características de cada clase. En el caso de *k*-medias, lo único que se conoce es el número de grupos.\n",
    "\n",
    "El objetivo del algoritmo de *k*-medias es particionar un conjunto de *n* datos en *k* grupos, asociando objetos cercanos y distinguiendo objetos diferentes. El resultado al final del procedimiento es la generación de un \"*prototipo de clase*\".\n",
    "\n",
    "En la imagen a continuación, se presentan 30 datos (puntos azules) que han sido agrupados en 4 clusters. Las líneas rojas representan fronteras (posibles) entre clase y las estrellas rojas representan prototipos de clase.\n",
    "\n",
    "![ ](images/k-means0.png)\n",
    "\n",
    "La clase es una generalización del cluster; una descripción conceptual del grupo representado por el conjunto de datos. La delimitación de una clase, construida de forma inductiva (a partir de ejemplos), suele no ser precisa: está limitada a los datos de que disponemos para modelarla, como se ilustra en la imagen siguiente. \n",
    "\n",
    "![ ](images/cluster-class.png)\n",
    "\n",
    "En esta imagen, los datos (ficticios) conocidos nos han permitido generar un modelo de clase (area en azul). Sin embargo, la clase real es diferente, sólo que al crear la clase no conocíamos suficientes datos para modelarla fielmente (como los datos señalados como puntos rojos). Considérese, por ejemplo, el siguiente conjunto de bicicletas:\n",
    "\n",
    "![ ](images/bicycles.png)\n",
    "\n",
    "A partir de los datos disponibles podemos concluir, por ejemplo, que todas las bicicletas tienen un asiento y pedales... sin embargo, esta definción de la clase bicicleta no incluye los siguientes ejemplares:\n",
    "\n",
    "[![ ](images/bicycles-2.png)](https://www.youtube.com/watch?v=KewMZ8sM0Uo)\n",
    "\n",
    "\n",
    "### Algoritmo\n",
    "\n",
    "El algoritmo k-means sigue los siguientes pasos (dado un conjunto de datos):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el ambiente\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from scipy.spatial import distance\n",
    "np.set_printoptions(precision=2, suppress=True) # Cortar la impresión de decimales a 1\n",
    "\n",
    "LARGER_DISTANCE = sys.maxsize\n",
    "TALK = True # TALK = True, imprime resultados parciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer los datos de archivo\n",
    "DATA_SET = pd.read_csv(\"data/datosProm.csv\", names = ['A', 'B']).values\n",
    "DATA_LEN = len(DATA_SET)\n",
    "\n",
    "# Definir una clase para expresar puntos y su asignación a un cluster\n",
    "# éste código no es necesario que sea comprendido, es para ilustrar los ejemplos\n",
    "class DataPoint:\n",
    "    def __init__(self, p):\n",
    "        self.value = p[:]\n",
    "        \n",
    "    def set_value(self, p):\n",
    "        self.value = p\n",
    "    \n",
    "    def get_value(self):\n",
    "        return self.value\n",
    "    \n",
    "    def set_cluster(self, cluster):\n",
    "        self.cluster = cluster\n",
    "    \n",
    "    def get_cluster(self):\n",
    "        return self.cluster\n",
    "\n",
    "data = []\n",
    "def initialize_dataset():\n",
    "    for i in range(DATA_LEN):\n",
    "        point = DataPoint(DATA_SET[i])\n",
    "        point.set_cluster(None)\n",
    "        data.append(point)\n",
    "    return\n",
    "\n",
    "# --------------------------\n",
    "# Crear el conjunto de datos\n",
    "initialize_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Definir el valor de $k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLUSTERS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Seleccionar de manera arbitraria *k* puntos en el espacio de características como centros iniciales de  los clusters (centroides o centros de masa).\n",
    "![ ](images/k-means1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroides inicializados en:\n",
      "[70.28, 42.125]\n",
      "[0.0, 56.75]\n",
      "[79.0, 2.5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir forma de muestreo; 0 = random, 1=head, 2=tail\n",
    "SAMPLING_METHOD = 1\n",
    "\n",
    "centroids = []\n",
    "def initialize_centroids():\n",
    "    if (TALK) : \n",
    "        print(\"Centroides inicializados en:\")\n",
    "    for c in range(NUM_CLUSTERS):\n",
    "        if (SAMPLING_METHOD == 0) :\n",
    "            which = random.randint(0,DATA_LEN-1)\n",
    "        elif (SAMPLING_METHOD == 1):\n",
    "            which = c\n",
    "        else :\n",
    "            which = DATA_LEN-1 - c\n",
    "                \n",
    "        centroids.append(list(DATA_SET[which]))\n",
    "        if (TALK) : \n",
    "            print(centroids[c])        \n",
    "    if (TALK) : \n",
    "        print()\n",
    "    \n",
    "    return\n",
    "\n",
    "# --------------------------\n",
    "# Inicializar los centroides\n",
    "initialize_centroids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Asignar cada punto del conjunto de datos al cluster donde la distancia del punto al centroide es menor.\n",
    "![ ](images/k-means2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El cluster  1  incluye  18 miembros.\n",
      "El cluster  2  incluye  7 miembros.\n",
      "El cluster  3  incluye  5 miembros.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def update_clusters():\n",
    "    changed = False\n",
    "    \n",
    "    for i in range(DATA_LEN):\n",
    "        minDistance = LARGER_DISTANCE\n",
    "        currentCluster = 0\n",
    "        \n",
    "        for j in range(NUM_CLUSTERS):\n",
    "            dist = distance.euclidean(data[i].get_value(), centroids[j])\n",
    "            if(dist < minDistance):\n",
    "                minDistance = dist\n",
    "                currentCluster = j\n",
    "        \n",
    "        if(data[i].get_cluster() is None or data[i].get_cluster() != currentCluster):\n",
    "            data[i].set_cluster(currentCluster)\n",
    "            changed = True\n",
    "            \n",
    "    members = [0] * NUM_CLUSTERS\n",
    "    for i in range(DATA_LEN):\n",
    "        members[data[i].get_cluster()] += 1\n",
    "    \n",
    "    if (TALK) : \n",
    "        for j in range(NUM_CLUSTERS):\n",
    "            print(\"El cluster \", j+1, \" incluye \", members[j], \"miembros.\")\n",
    "        print()\n",
    "            \n",
    "    return changed\n",
    "\n",
    "# --------------------------\n",
    "# Actualizar los clusters\n",
    "KEEP_WALKING = update_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Calcular los centroides a partir de los puntos en cada cluster. \n",
    "![ ](images/k-means3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los nuevos centroids son:\n",
      "[80.95777777777778, 73.79605555555554]\n",
      "[0.0, 73.88657142857141]\n",
      "[84.00999999999999, 6.466800000000001]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def update_centroids():    \n",
    "    if (TALK) : \n",
    "        print(\"Los nuevos centroids son:\")\n",
    "    for j in range(NUM_CLUSTERS):\n",
    "        means = [0] * DATA_SET.shape[1]\n",
    "            \n",
    "        clusterSize = 0\n",
    "        for k in range(len(data)):\n",
    "            if(data[k].get_cluster() == j):\n",
    "                p = data[k].get_value()\n",
    "                for i in range(DATA_SET.shape[1]):\n",
    "                    means[i] += p[i]\n",
    "                clusterSize += 1\n",
    "\n",
    "        if(clusterSize > 0):\n",
    "            for i in range(DATA_SET.shape[1]):\n",
    "                centroids[j][i] = means[i] / clusterSize\n",
    "\n",
    "        if (TALK) : \n",
    "            print(centroids[j])        \n",
    "    if (TALK) : \n",
    "        print()\n",
    "    \n",
    "    return\n",
    "\n",
    "# --------------------------\n",
    "# Actualizar los centroides\n",
    "update_centroids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Repetir los pasos 2 y 3 hasta que no haya cambios en los clusters.\n",
    "![ ](images/k-means4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El cluster  1  incluye  17 miembros.\n",
      "El cluster  2  incluye  7 miembros.\n",
      "El cluster  3  incluye  6 miembros.\n",
      "\n",
      "Los nuevos centroids son:\n",
      "[81.55529411764707, 76.07817647058822]\n",
      "[0.0, 73.88657142857141]\n",
      "[81.80833333333332, 11.222333333333333]\n",
      "\n",
      "El cluster  1  incluye  16 miembros.\n",
      "El cluster  2  incluye  7 miembros.\n",
      "El cluster  3  incluye  7 miembros.\n",
      "\n",
      "Los nuevos centroids son:\n",
      "[82.25999999999999, 78.20024999999998]\n",
      "[0.0, 73.88657142857141]\n",
      "[80.16142857142857, 15.637]\n",
      "\n",
      "El cluster  1  incluye  16 miembros.\n",
      "El cluster  2  incluye  7 miembros.\n",
      "El cluster  3  incluye  7 miembros.\n",
      "\n",
      "No más cambios.\n"
     ]
    }
   ],
   "source": [
    "while(KEEP_WALKING):\n",
    "    KEEP_WALKING = update_clusters()\n",
    "    if (KEEP_WALKING):\n",
    "        update_centroids()\n",
    "    else :\n",
    "        if (TALK) : \n",
    "            print (\"No más cambios.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplos lógicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estrategias de segmentación de mercado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/k-means_1.png\" alt=\"Drawing\" style=\"width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "si analizamos los datos podemos dividir los clientes de la siguiente manera:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/k_means_3.png\" alt=\"Drawing\" style=\"width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ejemplo clásico de k-means es el problema de las pizerías:\n",
    "    - Partimos de un estudio de mercado\n",
    "    - ¿Cuantas pizerías debemos crear?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/k_means_4.png\" alt=\"Drawing\" style=\"width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "segun el ojo humano serían 3, pero ¿cómo lo planteamos en un algoritmo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/k_means_5.png\" alt=\"Drawing\" style=\"width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos sucursales al azar, dentro del rango geográfico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/k_means_6.png\" alt=\"Drawing\" style=\"width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dos pasos esenciales ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/k_means_7.png\" alt=\"Drawing\" style=\"width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reubicar sucursales de acuerdo a estrategía de mercado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/k_means_8.png\" alt=\"Drawing\" style=\"width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repetir asignación de clientes de acuerdo a la sucursal más cercana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/k_means_9.png\" alt=\"Drawing\" style=\"width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entonces ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/k_means_10.png\" alt=\"Drawing\" style=\"width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reasignar centroides  y repetir ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/k_means_11.png\" alt=\"Drawing\" style=\"width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿fin ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/k_means_12.png\" alt=\"Drawing\" style=\"width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><i class=\"fa fa-lightbulb-o\" aria-hidden=\"true\"></i> <strong> Ejemplo de clustering </strong> https://www.youtube.com/watch?v=BVFG7fd1H30</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr style=\"border-width: 1px;\">\n",
    "\n",
    "El método $k$-means es un método muy robusto (aunque diversos autores han buscado maneras de eficientarlo, ver por ejemplo [este artículo](http://worldcomp-proceedings.com/proc/p2015/CSC2667.pdf) o [este otro](http://academics.smcvt.edu/jtrono/Papers/SMCClusteringPaper_DavidKronenberg.pdf). Su principal restricción es la __selección adecuada del número de clusters, $k$__ . En casos más interesantes que nuestro ejemplo, conviene realizar un análisis previo de determinación de clusters, por dendrogramas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\"><i class=\"fa fa-lightbulb-o\" aria-hidden=\"true\"></i> <strong> Más  sobre Clusterig</strong> http://scikit-learn.org/stable/modules/clustering.html#k-means</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo k-means es extremadamente fácil de implementar pero también es computacionalmente muy eficiente en comparación con otros algoritmos de clustering, lo que podría explicar su popularidad. El algoritmo $k$-means pertenece a la categoría de __clustering basado en prototipos__ . Existen otras dos categorías de clustering muy populares, __jerarquización__ y __agrupamiento basado en densidad__ . El agrupamiento basado en prototipos significa que cada grupo está representado por un prototipo, que puede ser el centroide (promedio) de puntos similares con características continuas, o el medoide (el punto más representativo o más frecuente) en el caso de las características categóricas. \n",
    "\n",
    "Mientras que $k$-means es muy bueno para identificar grupos de formas esféricas, uno de los inconvenientes de este algoritmo de agrupación es que tenemos que especificar el número de clústers $k$ a priori. Una elección inadecuada para $k$ puede dar como resultado un rendimiento de clúster pobre. Más adelante en este capítulo, discutiremos el método del codo y los diagramas de silueta, que son técnicas útiles para evaluar la calidad de una agrupación para ayudarnos a determinar la cantidad óptima de conglomerados $k$.\n",
    "\n",
    "\n",
    "Existen variantes de  $k$- Means (tambien llamado $C$-Means) que toman en cuenta  otros tipos de distancias o punto de los vectores protitipos (media, moda, etc.). Dos variantes populares son : k-medoids y fuzzy C-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means ++\n",
    "Hasta ahora, hemos discutido el algoritmo clásico _k-means_ que usa una semilla aleatoria para ubicar los centroides iniciales, lo que a veces puede resultar en agrupamientos incorrectos o convergencia lenta si los centroides iniciales se eligen mal. Una forma de abordar este problema es ejecutar el algoritmo k-means varias veces en un conjunto de datos y elegir el modelo de mejor rendimiento. \n",
    "\n",
    "Otra estrategia es __ubicar los centroides iniciales lejos el uno del otro a través del algoritmo _k-means_ ++__ , lo que conduce a mejores resultados y más consistentes que los medios k clásicos (D. Arthur y S. Vassilvitskii. K-means ++. Society for Industrial and Applied Mathematics, 2007).\n",
    "\n",
    "Otro problema con _k-means_ es que uno o más clusters pueden estar vacíos. Tenga en cuenta que este problema no existe para k-medoids o Fuzzy C-means, un algoritmo que discutiremos en la siguiente subsección. Sin embargo, este problema se tiene en cuenta en la implementación actual de k-medias en scikit-learn. Si un clúster está vacío, el algoritmo buscará la muestra más alejada del centro de gravedad del clúster vacío. Luego reasignará el centroide para que sea el punto más lejano\n",
    "\n",
    "\n",
    "### Hard vs soft clustering\n",
    "La agrupación en clúster duro describe una familia de algoritmos donde cada muestra de un conjunto de datos se asigna exactamente a un clúster, como en el algoritmo de k-medias que discutimos en la subsección anterior. Por el contrario, los algoritmos para clústeres blandos (a veces también denominados agrupamientos difusos) asignan una muestra a uno o más clústeres. Un ejemplo popular de clustering suave es el algoritmo C-means difuso (FCM) (también llamado soft k-means o fuzzy k-means). La idea original se remonta a la década de 1970, cuando Joseph C. Dunn propuso por primera vez una versión temprana de clustering difuso para mejorar k-means (_J. C. Dunn.\n",
    "A Fuzzy Relative of the Isodata Process and its Use in Detecting Compact Well-separated Clusters. 1973_). Casi una década después, James C. Bedzek publicó su trabajo sobre las mejoras del algoritmo de agrupamiento difuso, que ahora se conoce como el algoritmo FCM (_J. C. Bezdek. Pattern Recognition with Fuzzy Objective Function Algorithms.\n",
    "Springer Science & Business Media, 2013_)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X-Means\n",
    "\n",
    "Este algoritmo es una variante mejorada del K-Means. Su ventaja fundamental está en haber solucionado una de las mayores deficiencias presentadas en K-Means, el hecho de tener que __seleccionar a priori el número de clusters que se deseen obtener__ , a X-Means se le define un límite inferior K-min (número mínimo de clusters) y un límite superior K-Max (número máximo de clusters) y este algoritmo es capaz de obtener en ese rango el número óptimo de clusters, dando de esta manera más flexibilidad al usuario. Durante este proceso, el conjunto de centroides que alcanzan el mejor valor son almacenados, y estos serían la salida final, es decir, los valores finales de cada simulación de acuerdo a la distancia entre ellos. Los mismos son aplicables cuando en la Base de datos existen al menos 2 simulaciones para el modelo (que son ecuaciones formadas por arreglos de parámetros y condiciones iniciales). Se ha comprobado que sus resultados son más fiables que los obtenidos con el K-Means, debido a que presenta un valor de distorsión menor, son mucho mejor para realizar Clusters de un conjunto grande de datos y es incluso una variante mucho más rápida.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otros enfoques\n",
    "\n",
    "\n",
    "#### Cobweb\n",
    "\n",
    "Pertenece a la familia de algoritmos jerárquicos. Se caracteriza por la utilización de aprendizaje incremental, esto quiere decir, que realiza las agrupaciones instancia a instancia. Durante la ejecución del algoritmo se forma un árbol (árbol de clasificación) donde las hojas representan los segmentos y el nodo raíz engloba por completo el conjunto de datos. Al principio, el árbol consiste en un único nodo raíz. Las instancias se van añadiendo una a una y el árbol se va actualizando en cada paso. La clave para saber cómo y dónde se debe actualizar el árbol la proporciona una medida denominada utilidad de categoría, que mide la calidad general de una partición de instancias en un segmento. Pertenece a los métodos de aprendizaje conceptual o basado en modelos. Esto significa que cada cluster se considera como un modelo que puede describirse intrínsecamente, más que un ente formado por una colección de puntos. Además en el algoritmo también hay que tener en cuenta dos parámetros muy importantes:\n",
    "\n",
    "Acuity: es un parámetro muy necesario, pues la utilidad de categoría está basada en la estimación de la media y la desviación estándar del valor de un atributo para un nodo en particular, el resultado es 0 si dicho nodo solo tiene una instancia; por lo que se puede decir que el valor que toma este parámetro es la medida del error de un nodo con una sola instancia (establece la varianza mínima de un atributo).\n",
    "\n",
    "Cut-off: este parámetro es usado para evitar el crecimiento descontrolado de la cantidad de segmentos. Indica el grado de mejor ía que se debe producir en la utilidad de categoría para que la instancia se pueda tener en cuenta de manera individual. Resumiendo, cuando se va a añadir un nuevo nodo y no es suficiente el crecimiento de la utilidad de categoría, pues ese nodo se poda y la instancia pasa a otro nodo ya existente.\n",
    "\n",
    "#### EM\n",
    "\n",
    "Este algoritmo pertenece a una familia de modelos que se conocen como Finite Mixture Models, los cuales se pueden utilizar para segmentar conjuntos de datos. Está clasificado como un método de particionado y recolocación, o sea, Clustering Probabilístico. Se trata de obtener la FDP (Función de Densidad de Probabilidad) desconocida a la que pertenecen el conjunto completo de datos. El algoritmo EM, procede en dos pasos que se repiten de forma iterativa:\n",
    "\n",
    "Expectation: Utiliza los valores de los parámetros, iniciales o proporcionados por el paso Maximization, obteniendo diferentes formas de la FDP buscada.\n",
    "\n",
    "Maximization: Obtiene nuevos valores de los parámetros a partir de los datos proporcionados por el paso anterior.\n",
    "\n",
    "Finalmente se obtendrá un conjunto de clusters que agrupan el conjunto de proyectos original. Cada uno de estos cluster estará definido por los parámetros de una distribución "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
